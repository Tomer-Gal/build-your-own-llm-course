üß† Build Your Own LLM ‚Äî Course

Learn how to build a Large Language Model (LLM) from scratch, step by step ‚Äî from tokenization and transformer architecture to reasoning, fine-tuning, and reinforcement learning.
This course takes you beyond prompt engineering and API calls, giving you the practical understanding to engineer intelligence from first principles.

üîç What You‚Äôll Learn
* How tokens, embeddings, and attention mechanisms form the foundation of modern transformers
* Building and training Large Language Models (LLMs) from scratch, from architecture design to optimization and data pipelines
* Designing and implementing reasoning models capable of structured thought, multi-step problem solving, and chain-of-thought inference
* Applying Supervised Fine-Tuning (SFT) and LoRA (Low-Rank Adaptation) to specialize and adapt models efficiently
* Incorporating Reinforcement Learning (RL) techniques ‚Äî including RLHF, RLAIF, and self-improving feedback loops ‚Äî to align models with human or agentic objectives
* Engineering open, fully reproducible LLMs inspired by architectures like LLaMA, GPT-OSS, and DeepSeek, while focusing on transparency and hands-on training
* Scaling and fine-tuning across modern compute environments (multi-GPU, mixed precision, distributed training)
* Integrating your trained models into agentic systems that reason, plan, and act
* Deploying, serving, and evaluating LLMs for real-world use cases

üí° Who This Course Is For

Engineers, researchers, and AI enthusiasts who want to go beyond using APIs ‚Äî and learn how to build intelligence from first principles.

üë§ Author

Tomer Gal
Global CTO, Deloitte ‚Äî NVIDIA Alliance

R&D Leader, Zora - Deloitte's Agentic business

NVIDIA Deep Learning Institute Instructor - CUDA Python/C++/Multiple-GPUs, Deep Learning Fundamentals

Computer Science faculty member, Braude College of Engineering

Head of the Center of Excellence for AI in Finance, Reichman University
